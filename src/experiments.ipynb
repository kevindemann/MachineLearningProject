{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "from preprocessing import load_data, split_data\n",
    "from utils import load_image, visualization\n",
    "from augmentation import augment_data\n",
    "from classification import Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the provided MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (2000, 240)\n",
      "data lable shape: (2000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_path = \"../data/mfeat-pix\"\n",
    "\n",
    "\n",
    "img_shape = (16, 15)\n",
    "\n",
    "num_classes = 10\n",
    "samples_per_class = 200\n",
    "train_samples_per_class = 100\n",
    "test_samples_per_class = 100\n",
    "\n",
    "\n",
    "data = load_data(dataset_path)\n",
    "data_labels = np.repeat(np.arange(10), samples_per_class) #only possible as the data strucutre is known\n",
    "\n",
    "print(f'data shape: {data.shape}')\n",
    "print(f'data lable shape: {data_labels.shape}')\n",
    "\n",
    "load_image(data, data_labels, index = 879)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting data into train and test\n",
    "\n",
    "### As instructed, the data will be split 50/50, that is 1000 test images, and 1000 train images, each of which has 100 images per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train shape: (1000, 240)\n",
      "y train shape: (1000,)\n",
      "x test shape: (1000, 240)\n",
      "y test shape: (1000,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test = split_data(data, data_labels, num_classes, samples_per_class, train_samples_per_class)\n",
    "y_train, y_test = np.repeat(np.arange(10), train_samples_per_class), np.repeat(np.arange(10), train_samples_per_class)\n",
    "\n",
    "print(f'x train shape: {x_train.shape}')\n",
    "print(f'y train shape: {y_train.shape}')\n",
    "\n",
    "print(f'x test shape: {x_test.shape}')\n",
    "print(f'y test shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation\n",
    "\n",
    "Maybe also put this into experiments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train augmented shape: (5000, 240)\n",
      "y train augmented shape: (5000,)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)   #So that results may be re-produced\n",
    "\n",
    "augment_rotate = np.radians(12)\n",
    "num_versions = 4\n",
    "\n",
    "x_train_augmented = augment_data(x_train, img_shape, augment_rotate, num_versions)\n",
    "y_train_augmented = np.repeat(np.arange(10), (1+num_versions)*train_samples_per_class) #only possible as the data strucutre is known\n",
    "\n",
    "print(f'x train augmented shape: {x_train_augmented.shape}')\n",
    "print(f'y train augmented shape: {y_train_augmented.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New x augmented mean: -2.2997899880768577e-16\n",
      "New x augmented std: 0.9999999999999996\n",
      "\n",
      "\n",
      "New x mean: -1.2126596023639044e-16\n",
      "New x std: 0.9999999999999997\n"
     ]
    }
   ],
   "source": [
    "mean_a= np.mean(x_train_augmented)\n",
    "std_a = np.std(x_train_augmented)\n",
    "\n",
    "x_train_augmented = (x_train_augmented - mean_a)/std_a \n",
    "x_test_a = (x_test - mean_a)/std_a                         #standardize the test data whic is going to be used\n",
    "\n",
    "#Also standerdize the non augmented data for later testing on just the basic data\n",
    "mean= np.mean(x_train)\n",
    "std = np.std(x_train)\n",
    "\n",
    "x_train = (x_train - mean)/std\n",
    "x_test = (x_test - mean)/std   \n",
    "\n",
    "\n",
    "#checking if normalization worked\n",
    "print(f'New x augmented mean: {np.mean(x_train_augmented)}')\n",
    "print(f'New x augmented std: {np.std(x_train_augmented)}')\n",
    "print('\\n')\n",
    "print(f'New x mean: {np.mean(x_train)}')\n",
    "print(f'New x std: {np.std(x_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation\n",
    "\n",
    "### For every iteration of the model, 150 epochs will be run, and the loss function is categorical cross entropy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 300\n",
    "loss = 'cross_entropy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Single Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m model_1_a \u001b[38;5;241m=\u001b[39m Classifier(x_train_augmented, y_train_augmented, x_test_a, y_test, hidden_architecture_1) \n\u001b[1;32m      7\u001b[0m model_1_a\u001b[38;5;241m.\u001b[39mdata_schuffel()\n\u001b[0;32m----> 8\u001b[0m params_1_a, history_1_a  \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_1_a\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/AML/MachineLearningProject/src/classification.py:141\u001b[0m, in \u001b[0;36mClassifier.train\u001b[0;34m(self, data, params, loss, loss_params, optimizer, optimizer_params, batch_size, epochs, epoch_rate, seed)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_i_batch, y_i_batch \u001b[38;5;129;01min\u001b[39;00m batch_generator(x, y, batch_size, schuffel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, seed \u001b[38;5;241m=\u001b[39m seed): \u001b[38;5;66;03m#we go over each batch\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m loss \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcross_entropy\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         loss_i, param_grad \u001b[38;5;241m=\u001b[39m \u001b[43mvalue_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_i_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_i_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlambda_lasso\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlambda_ridge\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/api.py:717\u001b[0m, in \u001b[0;36mvalue_and_grad.<locals>.value_and_grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    715\u001b[0m   _check_input_dtype_grad(holomorphic, allow_int, leaf)\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n\u001b[0;32m--> 717\u001b[0m   ans, vjp_py \u001b[38;5;241m=\u001b[39m \u001b[43m_vjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_partial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdyn_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m   ans, vjp_py, aux \u001b[38;5;241m=\u001b[39m _vjp(\n\u001b[1;32m    720\u001b[0m       f_partial, \u001b[38;5;241m*\u001b[39mdyn_args, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/api.py:2205\u001b[0m, in \u001b[0;36m_vjp\u001b[0;34m(fun, has_aux, *primals)\u001b[0m\n\u001b[1;32m   2203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n\u001b[1;32m   2204\u001b[0m   flat_fun, out_tree \u001b[38;5;241m=\u001b[39m flatten_fun_nokwargs(fun, in_tree)\n\u001b[0;32m-> 2205\u001b[0m   out_primal, out_vjp \u001b[38;5;241m=\u001b[39m \u001b[43mad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprimals_flat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2206\u001b[0m   out_tree \u001b[38;5;241m=\u001b[39m out_tree()\n\u001b[1;32m   2207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:143\u001b[0m, in \u001b[0;36mvjp\u001b[0;34m(traceable, primals, has_aux)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvjp\u001b[39m(traceable, primals, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    142\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n\u001b[0;32m--> 143\u001b[0m     out_primals, pvals, jaxpr, consts \u001b[38;5;241m=\u001b[39m \u001b[43mlinearize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraceable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprimals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     out_primals, pvals, jaxpr, consts, aux \u001b[38;5;241m=\u001b[39m linearize(traceable, \u001b[38;5;241m*\u001b[39mprimals, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:132\u001b[0m, in \u001b[0;36mlinearize\u001b[0;34m(traceable, *primals, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m _, in_tree \u001b[38;5;241m=\u001b[39m tree_flatten(((primals, primals), {}))\n\u001b[1;32m    131\u001b[0m jvpfun_flat, out_tree \u001b[38;5;241m=\u001b[39m flatten_fun(jvpfun, in_tree)\n\u001b[0;32m--> 132\u001b[0m jaxpr, out_pvals, consts \u001b[38;5;241m=\u001b[39m \u001b[43mpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_to_jaxpr_nounits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjvpfun_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_pvals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m out_primals_pvals, out_tangents_pvals \u001b[38;5;241m=\u001b[39m tree_unflatten(out_tree(), out_pvals)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(out_primal_pval\u001b[38;5;241m.\u001b[39mis_known() \u001b[38;5;28;01mfor\u001b[39;00m out_primal_pval \u001b[38;5;129;01min\u001b[39;00m out_primals_pvals)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/profiler.py:335\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    334\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 335\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/interpreters/partial_eval.py:774\u001b[0m, in \u001b[0;36mtrace_to_jaxpr_nounits\u001b[0;34m(fun, pvals, instantiate)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m core\u001b[38;5;241m.\u001b[39mnew_main(JaxprTrace, name_stack\u001b[38;5;241m=\u001b[39mcurrent_name_stack) \u001b[38;5;28;01mas\u001b[39;00m main:\n\u001b[1;32m    773\u001b[0m   fun \u001b[38;5;241m=\u001b[39m trace_to_subjaxpr_nounits(fun, main, instantiate)\n\u001b[0;32m--> 774\u001b[0m   jaxpr, (out_pvals, consts, env) \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpvals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    775\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m env\n\u001b[1;32m    776\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m main, fun, env\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/linear_util.py:192\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m gen \u001b[38;5;241m=\u001b[39m gen_static_args \u001b[38;5;241m=\u001b[39m out_store \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    194\u001b[0m   \u001b[38;5;66;03m# Some transformations yield from inside context managers, so we have to\u001b[39;00m\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;66;03m# interrupt them before reraising the exception. Otherwise they will only\u001b[39;00m\n\u001b[1;32m    196\u001b[0m   \u001b[38;5;66;03m# get garbage-collected at some later time, running their cleanup tasks\u001b[39;00m\n\u001b[1;32m    197\u001b[0m   \u001b[38;5;66;03m# only after this exception is handled, which can corrupt the global\u001b[39;00m\n\u001b[1;32m    198\u001b[0m   \u001b[38;5;66;03m# state.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m   \u001b[38;5;28;01mwhile\u001b[39;00m stack:\n",
      "File \u001b[0;32m~/Desktop/AML/MachineLearningProject/src/classification.py:68\u001b[0m, in \u001b[0;36mANN.cross_entropy_loss\u001b[0;34m(self, params, x_input, y_labels, lamba_lasso, lambda_ridge)\u001b[0m\n\u001b[1;32m     66\u001b[0m log_probs \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mlog(y_probs) \n\u001b[1;32m     67\u001b[0m one_hot_labels \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mone_hot(y_labels, y_probs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])  \u001b[38;5;66;03m# Convert to one-hot encoding, and use the y_probes dims as the num of classes\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m l \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mjnp\u001b[38;5;241m.\u001b[39mmean(jnp\u001b[38;5;241m.\u001b[39msum(\u001b[43mone_hot_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlog_probs\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lamba_lasso \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     71\u001b[0m     l\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m lamba_lasso\u001b[38;5;241m*\u001b[39mjnp\u001b[38;5;241m.\u001b[39msum(jnp\u001b[38;5;241m.\u001b[39marray([jnp\u001b[38;5;241m.\u001b[39msum(jnp\u001b[38;5;241m.\u001b[39mabs(params[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m])) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(params) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m))]))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:264\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    262\u001b[0m args \u001b[38;5;241m=\u001b[39m (other, \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m swap \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m, other)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[0;32m--> 264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(other) \u001b[38;5;129;01min\u001b[39;00m _rejected_binop_types:\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/pjit.py:298\u001b[0m, in \u001b[0;36m_cpp_pjit.<locals>.cache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;129m@api_boundary\u001b[39m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcache_miss\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 298\u001b[0m   outs, out_flat, out_tree, args_flat, jaxpr, attrs_tracked \u001b[38;5;241m=\u001b[39m \u001b[43m_python_pjit_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m      \u001b[49m\u001b[43mjit_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m   executable \u001b[38;5;241m=\u001b[39m _read_most_recent_pjit_call_executable(jaxpr)\n\u001b[1;32m    301\u001b[0m   maybe_fastpath_data \u001b[38;5;241m=\u001b[39m _get_fastpath_data(\n\u001b[1;32m    302\u001b[0m       executable, out_tree, args_flat, out_flat, attrs_tracked, jaxpr\u001b[38;5;241m.\u001b[39meffects,\n\u001b[1;32m    303\u001b[0m       jit_info\u001b[38;5;241m.\u001b[39mabstracted_axes)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/pjit.py:167\u001b[0m, in \u001b[0;36m_python_pjit_helper\u001b[0;34m(jit_info, *args, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_pjit_helper\u001b[39m(jit_info, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    166\u001b[0m   args_flat, _, params, _, out_tree, _, _, _, arg_names, attrs_tracked \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m--> 167\u001b[0m       \u001b[43m_infer_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjit_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args_flat:\n\u001b[1;32m    169\u001b[0m     dispatch\u001b[38;5;241m.\u001b[39mcheck_arg(arg)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/pjit.py:567\u001b[0m, in \u001b[0;36m_infer_params\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(explicit_args):\n\u001b[1;32m    566\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     avals\u001b[38;5;241m.\u001b[39mappend(\u001b[43mshaped_abstractify\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    568\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOverflowError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     arg_path \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument path is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdbg\u001b[38;5;241m.\u001b[39marg_names[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dbg\n\u001b[1;32m    570\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflattened argument number is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/api_util.py:597\u001b[0m, in \u001b[0;36mshaped_abstractify\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshaped_abstractify\u001b[39m(x):\n\u001b[1;32m    596\u001b[0m   handler \u001b[38;5;241m=\u001b[39m _shaped_abstractify_handlers\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mtype\u001b[39m(x), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 597\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m handler(x) \u001b[38;5;28;01mif\u001b[39;00m handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_shaped_abstractify_slow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/api_util.py:579\u001b[0m, in \u001b[0;36m_shaped_abstractify_slow\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_shaped_abstractify_slow\u001b[39m(x):\n\u001b[1;32m    577\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m core\u001b[38;5;241m.\u001b[39mraise_to_shaped(\n\u001b[0;32m--> 579\u001b[0m       x \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, core\u001b[38;5;241m.\u001b[39mAbstractValue) \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_aval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    580\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/core.py:1478\u001b[0m, in \u001b[0;36mget_aval\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_aval\u001b[39m(x):\n\u001b[1;32m   1477\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, Tracer):\n\u001b[0;32m-> 1478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maval\u001b[49m\n\u001b[1;32m   1479\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m concrete_aval(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:468\u001b[0m, in \u001b[0;36mJVPTracer.aval\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maval\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    467\u001b[0m   \u001b[38;5;66;03m# TODO(dougalm): add epsilon ball\u001b[39;00m\n\u001b[0;32m--> 468\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_aval\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprimal\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/core.py:1480\u001b[0m, in \u001b[0;36mget_aval\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1478\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39maval\n\u001b[1;32m   1479\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1480\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_aval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/core.py:1469\u001b[0m, in \u001b[0;36mconcrete_aval\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1467\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m typ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__mro__\u001b[39m:\n\u001b[1;32m   1468\u001b[0m   handler \u001b[38;5;241m=\u001b[39m pytype_aval_mappings\u001b[38;5;241m.\u001b[39mget(typ)\n\u001b[0;32m-> 1469\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m handler: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__jax_array__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1471\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete_aval(x\u001b[38;5;241m.\u001b[39m__jax_array__())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/abstract_arrays.py:46\u001b[0m, in \u001b[0;36mcanonical_concrete_aval\u001b[0;34m(val, weak_type)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcanonical_concrete_aval\u001b[39m(val, weak_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 46\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mConcreteArray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanonicalize_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mweak_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweak_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/core.py:1720\u001b[0m, in \u001b[0;36mConcreteArray.__init__\u001b[0;34m(self, dtype, val, weak_type)\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype, val, weak_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1719\u001b[0m   \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m-> 1720\u001b[0m       \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m, dtype,\n\u001b[1;32m   1721\u001b[0m       weak_type\u001b[38;5;241m=\u001b[39mdtypes\u001b[38;5;241m.\u001b[39mis_weakly_typed(val) \u001b[38;5;28;01mif\u001b[39;00m weak_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m weak_type)\n\u001b[1;32m   1722\u001b[0m   dtypes\u001b[38;5;241m.\u001b[39mcheck_valid_dtype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m   1723\u001b[0m   \u001b[38;5;66;03m# Note: canonicalized self.dtype doesn't necessarily match self.val\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2022\u001b[0m, in \u001b[0;36mshape\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   1982\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1983\u001b[0m \u001b[38;5;124;03mReturn the shape of an array.\u001b[39;00m\n\u001b[1;32m   1984\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2019\u001b[0m \n\u001b[1;32m   2020\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2021\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2022\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n\u001b[1;32m   2023\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   2024\u001b[0m     result \u001b[38;5;241m=\u001b[39m asarray(a)\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/array.py:237\u001b[0m, in \u001b[0;36mArrayImpl.shape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    234\u001b[0m     addressable_da \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msharding\u001b[38;5;241m.\u001b[39m_addressable_device_assignment\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arrays \u001b[38;5;241m=\u001b[39m [device_id_to_buffer[device\u001b[38;5;241m.\u001b[39mid] \u001b[38;5;28;01mfor\u001b[39;00m device \u001b[38;5;129;01min\u001b[39;00m addressable_da]\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshape\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Shape:\n\u001b[1;32m    239\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maval\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    241\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdtype\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hidden_architecture_1 = [64]\n",
    "\n",
    "optimizer_1 = 'gd'\n",
    "\n",
    "\n",
    "model_1_a = Classifier(x_train_augmented, y_train_augmented, x_test_a, y_test, hidden_architecture_1) \n",
    "model_1_a.data_schuffel()\n",
    "params_1_a, history_1_a  = model_1_a.train(loss = loss, optimizer= optimizer_1, epochs = 150, batch_size = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'visualization' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mvisualization\u001b[49m(history_1_a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSingle Hidden Layer with 60 Neurons\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'visualization' is not defined"
     ]
    }
   ],
   "source": [
    "visualization(history_1_a, 'Single Hidden Layer with 60 Neurons')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Deeper Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_architecture_2_a_1 = [64, 64, 64]\n",
    "hidden_architecture_2_a_2 = [32, 64, 32]\n",
    "hidden_architecture_2_a_3 = [64, 32, 64]\n",
    "hidden_architecture_2_a_4 = [16, 32, 64]\n",
    "hidden_architecture_2_a_5 = [64, 32, 16]\n",
    "\n",
    "architecture_2_A= [[64, 64, 64], [32, 64, 32], [64, 32, 64], [16, 32, 64], [64, 32, 16]]\n",
    "\n",
    "models_2_a_A = []\n",
    "params_2_a_A = []\n",
    "histories_2_a_A = []\n",
    "accuracies_2_A = []\n",
    "\n",
    "optimizer_2 = 'gd'\n",
    "\n",
    "for architecture in architecture_2_A:\n",
    "    model_i_a = Classifier(x_train_augmented, y_train_augmented, x_test_a, y_test, architecture) \n",
    "    model_i_a.data_schuffel()\n",
    "    params_i_a, history_i_a  = model_i_a.train(loss = loss, optimizer= optimizer_2, epochs = 300, batch_size = 50, epoch_rate = 30)\n",
    "    accuracy_i_a = model_i_a.accuracy(params_i_a, x_test_a, y_test)\n",
    "    \n",
    "    \n",
    "    models_2_a_A.append(model_i_a)\n",
    "    params_2_a_A.append(params_2_a_A)\n",
    "    histories_2_a_A.append(history_i_a)\n",
    "    accuracies_2_A.append(accuracies_2_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Introducing Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#whichever one is best from above\n",
    "architecture_3 = []\n",
    "optimizer_3 = 'adam'\n",
    "\n",
    "\n",
    "model_3_a = Classifier(x_train_augmented, y_train_augmented, x_test_a, y_test, hidden_architecture_1) \n",
    "model_3_a.data_schuffel()\n",
    "params_3_a, history_3_a  = model_3_a.train(loss = loss, optimizer= optimizer_3, epochs = 150, batch_size = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization(history_3_a, f'Utilizing Adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Adding Ridge and Lasso Regularization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#whichever one is best from above\n",
    "architecture_4 = []\n",
    "optimizer_4 = 'adam'\n",
    "# shocase that all three can be utilized\n",
    "loss_params_4_A = [{'lambda_lasso': 0.01, 'lambda_ridge': 0.0}, {'lambda_lasso': 0.0, 'lambda_ridge': 0.001},{'lambda_lasso': 0.01, 'lambda_ridge': 0.001}]\n",
    "\n",
    "\n",
    "models_4_a_A = []\n",
    "params_4_a_A = []\n",
    "histories_4_a_A = []\n",
    "accuracies_4_A = []\n",
    "\n",
    "\n",
    "for loss_params in loss_params_4_A:\n",
    "    model_i_a = Classifier(x_train_augmented, y_train_augmented, x_test_a, y_test, architecture) \n",
    "    model_i_a.data_schuffel()\n",
    "    params_i_a, history_i_a  = model_i_a.train(loss = loss, loss_params= loss_params, optimizer= optimizer_4, epochs = 150, batch_size = 50, epoch_rate = 30)\n",
    "    accuracy_i_a = model_i_a.accuracy(params_i_a, x_test_a, y_test)\n",
    "    \n",
    "    \n",
    "    models_4_a_A.append(model_i_a)\n",
    "    params_4_a_A.append(params_2_a_A)\n",
    "    histories_4_a_A.append(history_i_a)\n",
    "    accuracies_4_A.append(accuracies_2_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a plot of all of them and table of accuracies between the fidderent values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initizlize the classification training class\n",
    "hidden_architecture_5 = [10, 50, 10]\n",
    "\n",
    "optimizer_5 = 'adam' \n",
    "\n",
    "search_params = {'alpha':[0.001], 'lasso':[0, 0.001], 'ridge':[0.01] ,  'batch':[128, 256]} \n",
    "\n",
    "\n",
    "model_5_a = Classifier(x_train_augmented, y_train_augmented, x_test_a, y_test, hidden_architecture_5)\n",
    "best_optimization_params, best_loss_params, best_batch_size = model_5_a.hyperparameter_search(5, loss, optimizer_5, search_params, epochs = 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result on Non-augmented Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiddem_architectura = []\n",
    "optimizer_final = 'adam'\n",
    "\n",
    "model_final_a = Classifier(x_train_augmented, y_train_augmented, x_test_a, y_test, hiddem_architectura)\n",
    "model_final_a.data_schuffel()\n",
    "params_final_a, history_final_a = model_final_a.train(loss = loss, loss_params= best_loss_params, optimizer= optimizer_final, optimizer_params = best_optimization_params, \n",
    "                                   epochs = 300, batch_size = best_batch_size, epoch_rate = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vsiaualize the results\n",
    "visualization(history_final_a, f'Utilizing Adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to Other Evaluated Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
